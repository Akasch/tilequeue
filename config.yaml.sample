queue:
  # type can be `sqs`, `file`, `mem`, or `redis`
  type: mem
  name: <sqs queue/queue file name/redis key>
store:
  type: s3 # Can also be `directory`, which would dump the tiles to disk.
  name: <s3 bucket/tile directory name>
  # The following store properties are s3 specific.
  path: osm
  reduced-redundancy: true
  date-prefix: 19851026
aws:
  # credentials are optional, and better to use an iam role assigned
  # to the instance if possible
  credentials:
    aws_access_key_id: <aws_access_key_id>
    aws_secret_access_key: <aws_secret_access_key>
tiles:
  seed:
    # can use any combination of the following options for the
    # tilequeue seed command

    # all tiles in a particular zoom range
    all:
      zoom-start: 0
      zoom-until: 10

    # parse the json from Mapzen's metro extracts for a particular
    # zoom range
    metro-extract:
      url: https://raw.githubusercontent.com/mapzen/metroextractor-cities/master/cities.json
      zoom-start: 11
      zoom-until: 15

      # Can also be set to an array of metro-extract city names, like
      # 'new-york_new-york', to only seed tiles from those areas
      # rather than all of them.
      cities:
        - new-york_new-york

    # parse the csv file from Mapbox's post on the top 50k most
    # requested tiles
    top-tiles:
      url: https://gist.github.com/brunosan/b7ce3df8b48229a61b5b/raw/37e42e77f253bc204076111c92acc4d5e653edd2/top_50k_tiles.csv
      zoom-start: 11
      zoom-until: 20

    # Specify any number of custom bounding boxes to seed tiles for.
    custom:
      zoom-start: 10
      zoom-until: 10

      # Must be set to an array of bounding boxes in `[left, bottom, right,
      # top]` (or `[min lon, min lat, max lon, max lat]`) format
      bboxes:

    # whether the tiles that are seeded should also be added to the
    # tiles of interest, or just enqueued
    should-add-to-tiles-of-interest: true

    # how many threads to use when enqueueing
    n-threads: 20

  intersect:
    # directory path to where expired tile files are generated
    expired-location: <path/to/expired/tiles/list>
    # the lowest zoom level to consider when enqueueing tiles to
    # process on update
    parent-zoom-until: 11

process:
  # number of simultaneous "querysets" to issue to the database.  The
  # query for each layer will be issued in parallel to the same
  # database. This can be 0 or unspecified, in which case the number
  # will be inferred from the number of database names configured
  # below.
  n-simultaneous-query-sets: 1
  # whether to print out the internal python queue sizes
  log-queue-sizes: true
  # and at what interval
  log-queue-sizes-interval-seconds: 30
  query-config: <path/to/vector-datasource/queries.yaml>
  template-path: <path/to/vector-datasource/queries>
  # whether to reload jinja query templates on each request. This
  # should be off in production.
  reload-templates: false
  # extensions of formats to generate
  # buffered Mapbox Vector Tiles are also possible by specifying mvtb
  formats: [json, topojson, mvt]
  # in addition to the `all` layer, any additional layers to also
  # store during processing
  layers-to-format:
    - layer: buildings
      formats: [json]
      zoom-start: 13
      zoom-until: 20
  # additionally, the data included for some formats expects to be
  # buffered. This is where buffers per layer or per geometry type can
  # be specified, with layers trumping geometry types
  buffer:
    mvtb:
      layer:
        earth: {point: 256}
        water: {point: 256}
        places: {point: 128}
      geometry:
        point: 64
        line: 8
        polygon: 8
logging:
  # logging.conf on this page:
  # https://docs.python.org/2/howto/logging.html#logging-basic-tutorial
  config: logging.conf.sample
redis:
  # stub or redis_client. The stub type can be useful for mocking out
  # tiles of interest and in flight enqueueing operations.
  type: stub
  host: localhost
  port: 6379
  db: 0
  cache-set-key: tilequeue.tiles-of-interest
# expected data source is postgresql
postgresql:
  host: localhost
  port: 5432
  # multiple databases can be specified, and these are iterated
  # through to balance query loads. This is useful when connecting to
  # pgbouncer, which can dispatch to different back end databases
  # based on the name.
  dbnames: [osm]
  user: osm
  password:

wof:
  # url path to neighbourhoods, microhoods, and macrohoods meta csv files
  neighbourhoods-meta-url: https://github.com/whosonfirst/whosonfirst-data/raw/master/meta/wof-neighbourhood-latest.csv
  microhoods-meta-url: https://github.com/whosonfirst/whosonfirst-data/raw/master/meta/wof-microhood-latest.csv
  macrohoods-meta-url: https://github.com/whosonfirst/whosonfirst-data/raw/master/meta/wof-macrohood-latest.csv
  boroughs-meta-url: https://github.com/whosonfirst/whosonfirst-data/raw/master/meta/wof-borough-latest.csv
  # url path prefix for wof raw data
  data-prefix-url: http://whosonfirst.mapzen.com/data
  # filesystem path to wof data checkout
  data-path: /tmp/whosonfirst-data
  postgresql:
    host: localhost
    port: 5432
    dbname: osm
    user: osm
    password:
